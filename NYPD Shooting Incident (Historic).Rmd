---
title: "NYPD_Shooting_Incident_Data (Historic)"
author: "VAsem"
date: "`r Sys.Date()`"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# About this Project

In this project we are going to analyze a list of every shooting incident that occurred in NYC going back to 2006 through the end of the previous calendar year. This data is manually extracted every quarter and reviewed by the Office of Management Analysis and Planning before being posted on the NYPD website. Each record represents a shooting incident in NYC and includes information about the event, the location and time of occurrence. In addition, information related to suspect and victim demographics is also included. 

# Before running the codes:
Please verify having installed the following libraries:
*Lubridate
*tidyverse
*readxl

# Source of the information

## NYPD Shooting Incident Information:
The information was downloaded from DATA.GOV, An official website of the United States government (https://catalog.data.gov/dataset). We looked specifically for the file "NYPD Shooting Incident Data (Historic)".

## New York Population information:
The NY borough's population information was obtained from "NYC Open Data" which consists of free public data published by New York City agencies and other partners (https://opendata.cityofnewyork.us/)

```{r}
library(tidyverse)
```

# Importing data

## First we are going to download the dataset "NYPD Shooting Incident Data Historic". Then we will create the dataframe named *"shooting_df"¨* for importing the link's data. Finally, given the amount of variables belonging to each sample, we are going to display the columns and their datatype by using the *sapply()* 
```{r}
url="https://data.cityofnewyork.us/api/views/833y-fsy8/rows.csv?accessType=DOWNLOAD"
shooting_df = read.csv(url,header = TRUE )
sapply(shooting_df, typeof)
```

The meaning of each column name can be found in the following link:
https://www.opendatanetwork.com/dataset/data.cityofnewyork.us/5ucz-vwe8

Here the description of the columns of interest for this study:

OCCUR_DATE                  Exact date of the shooting incident
OCCUR_TIME                  Exact time of the shooting incident
BORO          	            Borough where the shooting incident occurred
STATISTICAL_MURDER_FLAG     Shooting resulted in the victim’s death which would be counted as a murder
PERP_AGE_GROUP              Perpetrator’s age within a category
PERP_SEX                    Perpetrator’s sex description
PERP_RACE                   Perpetrator’s race description
VIC_AGE_GROUP               Victim’s age within a category
VIC_SEX	                    Victim’s sex description	
VIC_RACE                    Victim’s race description	

As it can be seen, this dataset doesn't contain the New York's population at the moment of each incident, so in order to calculate the number of incidents in a per-thousand-people basis, we need to get the population data of NY as well. For this aim, we need first to know the date range included in shooting_df (in order to look for the NY population in that range). The first measure for doing so is to extract the year of occurrence, so we first convert to m/d/Y format and then we extract just the year.(in this project we don't need the complete date, just the year of occurrence):
```{r}
shooting_df$OCCUR_DATE = as.POSIXct(shooting_df$OCCUR_DATE, format="%m/%d/%Y")    #Convert from character to m/d/y format
shooting_df$OCCUR_DATE = format(shooting_df$OCCUR_DATE, format = "%Y")            #keeps just the year of the date field
shooting_df = shooting_df %>%
  na.omit(OCCUR_DATE)                                   #Get rid of the na samples
head(shooting_df$OCCUR_DATE)
```
### The oldest date included in NYPD Shooting database can be found as follows:
```{r}
shooting_df %>% slice_min(OCCUR_DATE) %>% head(1)
```

### newer date included in NYPD Shooting database:
```{r}
shooting_df %>% slice_max(OCCUR_DATE) %>% head(1)
```
So the population we are going to look for ranges from 2006 to 2021. Now we will group the data in a per-year basis, then we are going to count the number of occurrences in a per-boro basis. Finally we will get rid of all data we don't need for this project.

```{r Number of shooting incidents per year}
shooting_df2=shooting_df %>% 
  group_by(BORO, OCCUR_DATE) %>% 
  summarise(occurrences = n()) %>%         #  summarise(cases = count(OCCUR_DATE))
  rename(Borough = "BORO") %>% 
  rename(Year = "OCCUR_DATE")

# Convert Year from Char to Integer
shooting_df2$Year = as.integer(shooting_df2$Year)
shooting_df2 = as.data.frame(shooting_df2)
head(shooting_df2)
```

## Import US Population:
All data will be acquired from https://data.cityofnewyork.us/, bellow the process of importing population data.

### Impor US Population for period 2020 to 2022
```{r Import NY population per borough}
url = "https://data.cityofnewyork.us/api/views/xywu-7bv9/rows.csv?accessType=DOWNLOAD&bom=true&format=true"
pop_2000_2030 = read.csv(url, header = TRUE, check.names = FALSE)
pop_2000_2030 = pop_2000_2030 %>% 
  select("Borough", "2000":"2030") %>% 
  select(-c("2000 - Boro share of NYC total", "2010 - Boro share of NYC total", "2020 - Boro share of NYC total"))

#the population is expressed as char with comma separator for thousands. We will
#remove commas and convert to number. Column 2 is "2000" and so on:
n=2
while(n<=5){
  pop_2000_2030[,n] = as.numeric(gsub(",", "", pop_2000_2030[,n]))
  n=n+1
}
pop_2000_2030
```

The NYPD shooting dataset contains per-year data from 2006 to 2021, while our population dataset (pop_2000_2030) only contains population data for 2000, 2020, 2020 and an extrapolation for 2030. So we need to interpolate for getting a population estimation for the years included in the NYPD dataset. For this aim, we are going to distribute the population growth evenly between the new columns to be added.

```{r}
#here we create columns 2001 to 2009
root=200
n = 1
while (n<=9) {
  name1=paste0(root,n)
  pop_2000_2030[,name1] = pop_2000_2030$"2000"  + n*(pop_2000_2030$"2010" - pop_2000_2030$"2000")/10
  
  n=n+1
}

#here we create columns 2011 to 2019
root=201
n = 1
while (n<=9) {
  name1=paste0(root,n)
  pop_2000_2030[,name1] = pop_2000_2030$"2010"  + n*(pop_2000_2030$"2020" - pop_2000_2030$"2010")/10
  
  n=n+1
}

#here we create column 2021
pop_2000_2030[,"2021"] = pop_2000_2030$"2020"  + (pop_2000_2030$"2030" - pop_2000_2030$"2020")/10

col_sequence = c(as.character(2000:2021))

pop_2000_2030 = pop_2000_2030[,c("Borough",col_sequence)]
pop_2000_2030
```

Now we are going to change the layout of the populatio table, putting the columns as rows:

```{r}
pop_2000_2030 = pop_2000_2030 %>% 
  pivot_longer(cols = c("2000":"2021"), 
               names_to = "Year",
               values_to = "Population")

#remove white spaces
pop_2000_2030$Borough = trimws(pop_2000_2030$Borough)                  

#Removes decimal places
pop_2000_2030$Population = format(round(pop_2000_2030$Population, 0), nsmall=0) 

#Changes to uppercase the Borough field
pop_2000_2030 = data.frame(lapply(pop_2000_2030, function(v) {
  if (is.character(v)) return(toupper(v))
  else return(v)
}))

#Convert to numeric
pop_2000_2030$Year = as.integer(pop_2000_2030$Year)
pop_2000_2030$Population = as.integer(pop_2000_2030$Population)
 
#Removes white spaces


pop_2000_2030
```

Now we are going to merge "shooting NYPD" and pop_2000_2030 datasets. We are going to insert an aditional column showing the per-thousand incidents:

```{r merging "shooting NYPD" and pop_2000_2030 datasets}
NYPD_dataset = merge(x=shooting_df2, y=pop_2000_2030, by=c("Borough","Year"), all.x = TRUE)
NYPD_dataset=NYPD_dataset %>% 
  mutate(cases_per_thou = 1000*occurrences/Population)
NYPD_dataset
```

# Data analysis:

## Boroughs with the highests accumulated incidents.

To determine this, we are going to group in a per-borough basis and then sort the boroughs depending on their accumulated incidents:

```{r Determining the boroughs with highests rates of incidents}
NYPD_dataset_accumulated = NYPD_dataset %>% 
  group_by(Borough) %>% 
  summarise(occurrences = sum(occurrences)) %>% 
  select(Borough, occurrences) %>% 
  slice_max(occurrences, n=5) %>% 
  ungroup()
NYPD_dataset_accumulated
```
So Brooklyn is the Borough with the highest accumulated number of incidents with 10334 cases during the period 2006-2021.

Now, let's see which borough exhibits the highest number of incidents per thousand people:

```{r Boroughs w/highest incident rates }
NYPD_dataset_rates = NYPD_dataset %>% 
  group_by(Borough) %>% 
  summarise(cases_per_thou = max(cases_per_thou)) %>% 
  select(Borough, cases_per_thou) %>% 
  slice_max(cases_per_thou, n=5) %>% 
  ungroup()
NYPD_dataset_rates
```
We can verify that the highest incident rate belongs to BRONX, while the QUEENS has the lowest incident rate.

# Visualizing our data:

Now it´s time to analyze the data in a graphical way. The first think to do is to transform NYPD_dataset_rates in such a way that each borough becomes a column. This in order to being able to graph different borough data into the same graph. 

```{r}
BRONX_DF = NYPD_dataset %>% 
  filter(Borough == "BRONX") %>% 
  select(Year, BRONX_cases_per_thou = cases_per_thou)

BROOKLYN_DF = NYPD_dataset %>% 
  filter(Borough == "BROOKLYN") %>%
  select(Year, BROOKLYN_cases_per_thou = cases_per_thou)

MANHATTAN_DF = NYPD_dataset %>% 
  filter(Borough == "MANHATTAN") %>%
  select(Year, MANHATTAN_cases_per_thou = cases_per_thou)

QUEENS_DF = NYPD_dataset %>% 
  filter(Borough == "QUEENS") %>%
  select(Year, QUEENS_cases_per_thou = cases_per_thou)

STATEN_ISLAND_DF = NYPD_dataset %>% 
  filter(Borough == "STATEN ISLAND") %>%
  select(Year, STATEN_ISLAND_cases_per_thou = cases_per_thou)

NYC_DF = list(BRONX_DF, BROOKLYN_DF, MANHATTAN_DF, QUEENS_DF, STATEN_ISLAND_DF)
NYC_DF = NYC_DF %>% 
  reduce(full_join, by="Year")

NYC_DF
```

Now it time to put all the data into a single graph:

```{r Visualizing our data}

NYC_DF %>% 
  ggplot(aes(x=Year)) +
  geom_line(aes(y=BRONX_cases_per_thou, color = "BRONX_cases_per_thou")) +
  geom_point(aes(y=BRONX_cases_per_thou, color = "BRONX_cases_per_thou")) + 
  geom_line(aes(y=BROOKLYN_cases_per_thou, color = "BROOKLYN_cases_per_thou")) + 
  geom_point(aes(y=BROOKLYN_cases_per_thou, color = "BROOKLYN_cases_per_thou")) + 
  geom_line(aes(y=MANHATTAN_cases_per_thou, color = "MANHATTAN_cases_per_thou")) + 
  geom_point(aes(y=MANHATTAN_cases_per_thou, color = "MANHATTAN_cases_per_thou")) + 
  geom_line(aes(y=QUEENS_cases_per_thou, color = "QUEENS_cases_per_thou")) + 
  geom_point(aes(y=QUEENS_cases_per_thou, color = "QUEENS_cases_per_thou")) + 
  geom_line(aes(y=STATEN_ISLAND_cases_per_thou, color = "STATEN_ISLAND_cases_per_thou")) +
  geom_point(aes(y=STATEN_ISLAND_cases_per_thou, color = "STATEN_ISLAND_cases_per_thou")) + 
  labs(title = "NYPD Shooting Incidents [per thousand people]", y=NULL)
```
```{r Visualizing our data: Piechart}
bp<- ggplot(NYPD_dataset_accumulated, aes(x="", y=occurrences, fill=Borough)) +
geom_bar(width = 0.5, stat = "identity") 
bp

```

# Modeling the information

Now we are going to look at a linear model. So a linear model means the variable
I want to look at is predicted by other variables in a linear fashion. Below we
are going to look at the quantity of incidents occurred in BRONX and see how well a lm fits to this data:

## Linear Model 1:

```{r}
qplot(Year, BRONX_cases_per_thou, data = NYC_DF, geom="point") + 
  geom_smooth(method = "lm", se= FALSE)
```

## Linear Model 2:

We can verify that the model fits very well to the data, mainly up to 2019. In fact, if we  take just the values up to 2019:

```{r}
NYC_DF_2019 = NYC_DF %>% 
   filter(Year <= 2019)
qplot(Year, BRONX_cases_per_thou, data = NYC_DF_2019, geom="point") + 
  geom_smooth(method = "lm", se= FALSE)
```


# Bias analysis:

I guess, my main source of bias was on the fields I selected for the analysis. The NYPD Shooting incident dataset offered a lot of fields that were dismissed in this project: Perpetrator/Victim Sex, Perpetrator/Victim Race, Age Group, etc. My own mindset led me to select just the numbers of incidents and the year they were commited, without taking into account the rest of the variables.


# Genaral Conclusions:

Regarding the graphical information, we can conclude:

1) Al borough were experiencing a more or less sustained decline from 2006, reaching it's lowest values during 2018-2019. Then, all borough experienced a dramatic increase in the shooting incidents by 2020 (possibly due to the end of the lockdown). Finally, Brooklyn, Queens and Staten Island decreased their shooting by 2021, except Bronx and Manhattan. 

2) The highest shooting incidents in a per thousand people basis belong to Bronx and Brooklyn along the whole period of analysis.

3) The greatest accumulated number of incidents (in absolute terms) belongs to BROOKLYN with 10334 events during the period under analysis.

4) It's possible other useful insights have been disregarded due to my own biases at the moment of selecting the variables to be included in the project.





